\chapter{Introduction}
%
%
The field of \textit{machine learning} emerged in the 1950s \cite{samuel1959some, rosenblatt1958perceptron}, motivated by the idea of letting a computer discover algorithms and patterns without having to explicitly arrange them by hand. After the initial phase and multiple \enquote{AI-winters} \cite{steele1996evolution}, numerous important developments---e.g. the rediscovery of the backpropagation algorithm, originally due to \cite{kelley1960gradient,rosenblatt1962principles} and then popularized in \cite{rumelhart1986learning}, see e.g. \cite{schmidhuber2022annotated}---contributed to the relevance of learning methods. The advances in computer hardware together with the availability of large amounts of data, finally allowed the machine learning enthusiasm of the recent years to spark. While \enquote{deep} learning methods---i.e. techniques involving many stacked neural layers as originally proposed in \cite{rosenblatt1958perceptron}---are the most prominent examples, there is a whole zoo of learning-based strategies that are actively applied in fields like computer vision \cite{chai2021deep}, natural language processing \cite{khurana2023natural} or healthcare \cite{shehab2022machine}. In this work we mainly focus on data-driven approaches, applied to classification tasks, where the concrete modality of the given data determines our approach. Namely, we focus on supervised---the dataset consists only of input-output pairs, i.e. is fully labeled---and semi-supervised---the data is only partially labeled---learning tasks.

For both regimes especially the last 20 years have seen great success of these data-driven methods. However, the sometimes purely heuristic learning strategies also exhibit serious drawbacks. In the supervised setting one is usually interested in the generalization behavior of a learned classifier, i.e. how good is the performance on unseen inputs which are not part of the given training data. Unfortunately in \cite{goodfellow2014explaining} it was discovered, that this performance can be completely corrupted, by small, seemingly invisible perturbations known as \textit{adversarial attacks}. More generally this phenomenon leads us to the issue of \textit{input robustness}. Given some input $\inp$, suppose that a human and some machine would classify this input to be of type $c$. In a rather vague but demonstrative formulation, the key implication we want to obtain for an input $\inpp$ is
%
\begin{align*}
\left.
\begin{gathered}
\inpp\text{ is close to }\inp,\\
\inpp\text{ is still classified as }c\text{ by a human}
\end{gathered}
\right\}
\Rightarrow
\text{the machine classifies }\inpp\text{ as } c. 
\end{align*}
%
Next to adversarial examples this also includes resolution changes of images, which do not change the classification by a human, if they are reasonably small. In any case, the existence of these perturbations exhibit critical flaws of learning methods and call for a better theoretical understanding of the employed models. This is where the mathematical foundation of the field becomes more relevant and properties apart from the classification performance come into play, which are discussed within this thesis.

For the semi-supervised setting we consider graph-based algorithms as originally proposed in \cite{zhu2003semi} with the graph Laplacian. The main problem we highlight in this thesis was first observed in \cite{nadler2009statistical}, namely that the classification performance deters significantly with increasing dimensionality of the data. In fact it turned out that solutions obtained by the standard graph Laplacian tend to be constant over the whole dataset, whenever the dimension is larger than two, which can be related to the Sobolev embedding theorem \cite{adams2003sobolev}. This issue is prevalent in the infinite data-limit, where a priori we consider the case, when the amount of unlabeled data points goes to infinity, which leads us to the question of \textit{consistency} for semi-supervised algorithms.

An issue that is shared across the supervised and semi-supervised setting is the high demand for computational resources. Training a neural network usually involves the use of GPUs for long amounts of time. On the one hand this makes the process infeasible for less powerful machines or even mobile devices and on the other hand generates questionable amounts of $\mathrm{CO_2}$ emissions \cite{hoefler2021sparsity}. For graph-based semi-supervised learning one first needs to compute distances between many different data points, to obtain edge weights, which itself is a costly task. Furthermore, the computational complexity of various tasks on a given graph, scales with the number of edges. For example, the run time for Dijkstra's algorithm to compute shortest paths on a graph, already scales linearly with the amount of edges \cite{dijkstra2022note}. In this thesis, the keyword to reduce the computational load in both cases, is \textit{sparsity}. The concept of sparse matrices routes deeply into the field of numerical linear algebra \cite{lanczos1952solution,golub2013matrix} and basically consists of exploiting zeros in a matrix to speed up the computation time. For neural networks this can be incorporated by enforcing the weight matrices of the layers to be sparse. For graphs, sparsity of the connectivity matrix simply means that we have only a small amount of active edges, which also reduces computational cost.
%
%
\paragraph{Contributions in This Work}
%
Taking up the previously mentioned subjects this thesis is concerned with \textit{consistency, robustness} and \textit{sparsity} of supervised and semi-supervised learning algorithms. 

For the latter we mainly consider the so-called Lipschitz learning task \cite{nadler2009statistical} for which we prove convergence and convergence rates for discrete solutions to their continuum counterpart in the infinite data limit. Here, we always work in a framework that allows for very sparse and therefore computationally feasible graphs.

In the supervised regime we deal with input-robustness w.r.t. adversarial attacks and resolution changes. In the first case we propose an efficient algorithm, penalizing the Lipschitz constant \cite{lipschitz1877lehrbuch} of a neural network, which trains an adversarially robust network. In the multi-resolution setting we analyze the role of Fourier neural operators as proposed in \cite{li2020fourier} and their connection to standard convolutional neural layers \cite{fukushima1980neocognitron}. Concerning the computational complexity of neural network training, we propose an algorithm based on Bregman iterations \cite{osher2005iterative} that allows for sparse weight matrices throughout the training. We also provide the convergence analysis for the stochastic adaption of the original Bregman iterations.

\paragraph{Structure of The Exposition} In \cref{ch:para} we introduce the learning paradigms and basic notions used throughout this thesis. We then present the topics on consistency for semi-supervised learning on graphs in \cref{ch:SSL}. After an explanatory introduction we then highlight the main contributions of \cite{roith2022continuum,bungert2021uniform}. Here, we try to have as little redundancy to the prints in \cref{part:Prints} as possible, while still allowing for an understandable context. In \cref{ch:SL} we then comment on the supervised part of this thesis. After an additional introduction the chapter contains three section presenting the works \cite{kabri2023resolution,bungert2021clip,bungert2022bregman} individually. Finally, in \cref{ch:C} we summarize the contents of the whole thesis and provide possible future directions.

